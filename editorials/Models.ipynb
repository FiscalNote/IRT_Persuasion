{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irt_lib.editorial_data_helper import create_full_data\n",
    "\n",
    "from irt_lib.helpers import split_by_doc_id, do_metrics, run_full_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data = create_full_data(feature_types=['style_scaled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feats</th>\n",
       "      <th>user_id</th>\n",
       "      <th>label</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.9675265502110052, -1.2649550896245798, 2.21...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1638699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.5305433924314203, -1.0457320355012902, 1.96...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1640113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.5755031175565148, 0.4355048166830996, -0.63...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1640630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.036562431463193934, -1.393328950147228, -0....</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1640915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.9675265502110052, -1.2649550896245798, 2.21...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1638699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               feats  user_id  label   doc_id\n",
       "0  [0.9675265502110052, -1.2649550896245798, 2.21...        3   True  1638699\n",
       "1  [0.5305433924314203, -1.0457320355012902, 1.96...        3   True  1640113\n",
       "2  [1.5755031175565148, 0.4355048166830996, -0.63...        3  False  1640630\n",
       "3  [0.036562431463193934, -1.393328950147228, -0....        3   True  1640915\n",
       "4  [0.9675265502110052, -1.2649550896245798, 2.21...        2   True  1638699"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Prior Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average User Prior: 0.6562835355607319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "accs = []\n",
    "for train_index, test_index in kf.split(style_data):\n",
    "    train = style_data.iloc[train_index]\n",
    "    test = style_data.iloc[test_index]\n",
    "    \n",
    "    priors = train.groupby('user_id').label.mean().to_dict()\n",
    "    \n",
    "    y_pred = test.user_id.map(lambda x: random.random() < priors.get(x))\n",
    "    accs.append(accuracy_score(test.label, y_pred))\n",
    "\n",
    "print(\"Average User Prior:\", sum(accs) / len(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.models import IRTNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = len(style_data.iloc[0].feats)\n",
    "num_users = style_data.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arguments = {'D_in': D_in, 'num_users': num_users}\n",
    "train_arguments = {'num_train_epochs': 200, 'learning_rate': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = IRTNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58800' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58800/58800 02:45, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.572300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.557200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.546700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.535800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.524300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-50000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1176\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round {'test_loss': 0.548729419708252, 'test_macro_f1': 0.6774964573808007, 'test_micro_f1': 0.745748299319728, 'test_pos_f1': 0.8258590564938846, 'test_accuracy': 0.7457482993197279, 'test_runtime': 0.37, 'test_samples_per_second': 3177.958, 'test_steps_per_second': 397.245}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2637' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2637/58800 00:07 < 02:38, 355.31 it/s, Epoch 4.48/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0409f7ebb928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mtrain_arguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mtrain_arguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_train_epochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_full_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_cls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_arguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_arguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maveraged\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mfinal_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/DS-Argument-Research/AdvocacyProject/lib/helpers.py\u001b[0m in \u001b[0;36mrun_full_cv\u001b[0;34m(data, model_class, model_args, training_args, averaged)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1355\u001b[0m                             nn.utils.clip_grad_norm_(\n\u001b[1;32m   1356\u001b[0m                                 \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaster_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_apex\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m                                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m                             )\n\u001b[1;32m   1359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclip_coef\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for C in [1e-3, 1e-4, 1e-5, 1e-6]:\n",
    "    for reg_type in ['l1', 'l2']:\n",
    "        for learning_rate in [0.01, 0.005]:\n",
    "            model_arguments['C'] = C\n",
    "            model_arguments['reg_type'] = reg_type\n",
    "            train_arguments['learning_rate'] = learning_rate\n",
    "            train_arguments['num_train_epochs'] = 100\n",
    "            results = run_full_cv(style_data, model_cls, model_arguments, train_arguments, averaged=True)\n",
    "            \n",
    "            final_results[(C, reg_type, learning_rate)] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.548729419708252,\n",
       " 'test_macro_f1': 0.6774964573808007,\n",
       " 'test_micro_f1': 0.745748299319728,\n",
       " 'test_pos_f1': 0.8258590564938846,\n",
       " 'test_accuracy': 0.7457482993197279,\n",
       " 'test_runtime': 0.37,\n",
       " 'test_samples_per_second': 3177.958,\n",
       " 'test_steps_per_second': 397.245}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(final_results, open('style_scaled_cv_results.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_full_data(feature_types=['text_lemma_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in [1e-3, 1e-4, 1e-5, 1e-6]:\n",
    "    for reg_type in ['l1', 'l2']:\n",
    "        for learning_rate in [0.01, 0.005]:\n",
    "            model_arguments['C'] = C\n",
    "            model_arguments['reg_type'] = reg_type\n",
    "            train_arguments['learning_rate'] = learning_rate\n",
    "            train_arguments['num_train_epochs'] = 100\n",
    "            results = run_full_cv(style_data, model_cls, model_arguments, train_arguments, averaged=True)\n",
    "            \n",
    "            final_results[(C, reg_type, learning_rate)] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style + Text Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_full_data(feature_types=['style_scaled', 'text_lemma_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58800' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58800/58800 02:47, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.573100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.559900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.548800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.537900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.526400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-50000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1176\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round {'test_loss': 0.5318859815597534, 'test_macro_f1': 0.6913175569815126, 'test_micro_f1': 0.7542517006802723, 'test_pos_f1': 0.8306971294669011, 'test_accuracy': 0.7542517006802721, 'test_runtime': 0.3716, 'test_samples_per_second': 3164.771, 'test_steps_per_second': 395.596}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58800' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58800/58800 02:46, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.543800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.525600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.521100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.514700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-50000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1176\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round {'test_loss': 0.5549741387367249, 'test_macro_f1': 0.6776125993523698, 'test_micro_f1': 0.7465986394557823, 'test_pos_f1': 0.8267441860465117, 'test_accuracy': 0.7465986394557823, 'test_runtime': 0.3716, 'test_samples_per_second': 3164.988, 'test_steps_per_second': 395.624}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58800' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58800/58800 02:51, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.542700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.528200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.516100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.506500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.494600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-50000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1176\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round {'test_loss': 0.5408536195755005, 'test_macro_f1': 0.6759811616954474, 'test_micro_f1': 0.7440476190476191, 'test_pos_f1': 0.8244897959183672, 'test_accuracy': 0.7440476190476191, 'test_runtime': 0.3715, 'test_samples_per_second': 3165.222, 'test_steps_per_second': 395.653}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58800' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58800/58800 02:51, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.517400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.504100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.497500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.492900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.486400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-50000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1176\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round {'test_loss': 0.5402262210845947, 'test_macro_f1': 0.6781341107871719, 'test_micro_f1': 0.745748299319728, 'test_pos_f1': 0.8256559766763848, 'test_accuracy': 0.7457482993197279, 'test_runtime': 0.3692, 'test_samples_per_second': 3185.683, 'test_steps_per_second': 398.21}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58800' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58800/58800 02:47, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.537200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.522200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.500300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.488400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-50000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1176\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round {'test_loss': 0.5384057760238647, 'test_macro_f1': 0.6773756963673674, 'test_micro_f1': 0.7448979591836735, 'test_pos_f1': 0.824970828471412, 'test_accuracy': 0.7448979591836735, 'test_runtime': 0.3698, 'test_samples_per_second': 3179.748, 'test_steps_per_second': 397.469}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58800' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58800/58800 02:47, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.512100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.498100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.491400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.486700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.480200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-50000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1176\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round {'test_loss': 0.5377528667449951, 'test_macro_f1': 0.6758615654205608, 'test_micro_f1': 0.7431972789115646, 'test_pos_f1': 0.8235981308411214, 'test_accuracy': 0.7431972789115646, 'test_runtime': 0.3733, 'test_samples_per_second': 3150.701, 'test_steps_per_second': 393.838}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58800' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58800/58800 02:51, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.534000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.518800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.506400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.496600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.484700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-50000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1176\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round {'test_loss': 0.5372947454452515, 'test_macro_f1': 0.6744694671238171, 'test_micro_f1': 0.7423469387755102, 'test_pos_f1': 0.8231173380035026, 'test_accuracy': 0.7423469387755102, 'test_runtime': 0.375, 'test_samples_per_second': 3136.299, 'test_steps_per_second': 392.037}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58800' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58800/58800 02:51, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.509000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.494700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.487800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.483100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.476600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-50000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1176\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round {'test_loss': 0.5365754961967468, 'test_macro_f1': 0.6758615654205608, 'test_micro_f1': 0.7431972789115646, 'test_pos_f1': 0.8235981308411214, 'test_accuracy': 0.7431972789115646, 'test_runtime': 0.3702, 'test_samples_per_second': 3176.824, 'test_steps_per_second': 397.103}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58800' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58800/58800 02:46, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.533300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.518000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.505600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.495900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.483900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-50000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1176\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round {'test_loss': 0.5372939109802246, 'test_macro_f1': 0.673714953271028, 'test_micro_f1': 0.7414965986394558, 'test_pos_f1': 0.822429906542056, 'test_accuracy': 0.7414965986394558, 'test_runtime': 0.3683, 'test_samples_per_second': 3192.878, 'test_steps_per_second': 399.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58800' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58800/58800 02:47, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.508400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.493900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.487100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.482400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.475900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-50000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1176\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round {'test_loss': 0.5365563631057739, 'test_macro_f1': 0.6758615654205608, 'test_micro_f1': 0.7431972789115646, 'test_pos_f1': 0.8235981308411214, 'test_accuracy': 0.7431972789115646, 'test_runtime': 0.3757, 'test_samples_per_second': 3130.495, 'test_steps_per_second': 391.312}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58800' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58800/58800 02:50, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.517700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.505300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.495500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.483500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-50000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1176\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round {'test_loss': 0.5372176766395569, 'test_macro_f1': 0.6729613193879012, 'test_micro_f1': 0.7406462585034015, 'test_pos_f1': 0.8217416715371128, 'test_accuracy': 0.7406462585034014, 'test_runtime': 0.3675, 'test_samples_per_second': 3199.958, 'test_steps_per_second': 399.995}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58800' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58800/58800 02:53, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.508100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.493600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.486700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.482000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.475500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-50000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1176\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round {'test_loss': 0.5364736318588257, 'test_macro_f1': 0.6751058353263412, 'test_micro_f1': 0.7423469387755102, 'test_pos_f1': 0.8229105786090006, 'test_accuracy': 0.7423469387755102, 'test_runtime': 0.3684, 'test_samples_per_second': 3191.95, 'test_steps_per_second': 398.994}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58800' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58800/58800 02:46, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.532900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.517600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.505200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.495400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.483400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-50000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1176\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4698\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 58800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished round {'test_loss': 0.5372108817100525, 'test_macro_f1': 0.6729613193879012, 'test_micro_f1': 0.7406462585034015, 'test_pos_f1': 0.8217416715371128, 'test_accuracy': 0.7406462585034014, 'test_runtime': 0.3778, 'test_samples_per_second': 3112.544, 'test_steps_per_second': 389.068}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46953' max='58800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46953/58800 02:13 < 00:33, 351.47 it/s, Epoch 79.85/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.493500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.486600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.481900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /home/ec2-user/temp_cv_path/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    }
   ],
   "source": [
    "for C in [1e-3, 1e-4, 1e-5, 1e-6]:\n",
    "    for reg_type in ['l1', 'l2']:\n",
    "        for learning_rate in [0.01, 0.005]:\n",
    "            model_arguments['C'] = C\n",
    "            model_arguments['reg_type'] = reg_type\n",
    "            train_arguments['learning_rate'] = learning_rate\n",
    "            train_arguments['num_train_epochs'] = 100\n",
    "            results = run_full_cv(style_data, model_cls, model_arguments, train_arguments, averaged=True)\n",
    "            \n",
    "            final_results[(C, reg_type, learning_rate)] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0.001, 'l1', 0.01): {'test_loss': 0.5318859815597534,\n",
       "  'test_macro_f1': 0.6913175569815126,\n",
       "  'test_micro_f1': 0.7542517006802723,\n",
       "  'test_pos_f1': 0.8306971294669011,\n",
       "  'test_accuracy': 0.7542517006802721,\n",
       "  'test_runtime': 0.3716,\n",
       "  'test_samples_per_second': 3164.771,\n",
       "  'test_steps_per_second': 395.596},\n",
       " (0.001, 'l1', 0.005): {'test_loss': 0.5549741387367249,\n",
       "  'test_macro_f1': 0.6776125993523698,\n",
       "  'test_micro_f1': 0.7465986394557823,\n",
       "  'test_pos_f1': 0.8267441860465117,\n",
       "  'test_accuracy': 0.7465986394557823,\n",
       "  'test_runtime': 0.3716,\n",
       "  'test_samples_per_second': 3164.988,\n",
       "  'test_steps_per_second': 395.624},\n",
       " (0.001, 'l2', 0.01): {'test_loss': 0.5408536195755005,\n",
       "  'test_macro_f1': 0.6759811616954474,\n",
       "  'test_micro_f1': 0.7440476190476191,\n",
       "  'test_pos_f1': 0.8244897959183672,\n",
       "  'test_accuracy': 0.7440476190476191,\n",
       "  'test_runtime': 0.3715,\n",
       "  'test_samples_per_second': 3165.222,\n",
       "  'test_steps_per_second': 395.653},\n",
       " (0.001, 'l2', 0.005): {'test_loss': 0.5402262210845947,\n",
       "  'test_macro_f1': 0.6781341107871719,\n",
       "  'test_micro_f1': 0.745748299319728,\n",
       "  'test_pos_f1': 0.8256559766763848,\n",
       "  'test_accuracy': 0.7457482993197279,\n",
       "  'test_runtime': 0.3692,\n",
       "  'test_samples_per_second': 3185.683,\n",
       "  'test_steps_per_second': 398.21},\n",
       " (0.0001, 'l1', 0.01): {'test_loss': 0.5384057760238647,\n",
       "  'test_macro_f1': 0.6773756963673674,\n",
       "  'test_micro_f1': 0.7448979591836735,\n",
       "  'test_pos_f1': 0.824970828471412,\n",
       "  'test_accuracy': 0.7448979591836735,\n",
       "  'test_runtime': 0.3698,\n",
       "  'test_samples_per_second': 3179.748,\n",
       "  'test_steps_per_second': 397.469},\n",
       " (0.0001, 'l1', 0.005): {'test_loss': 0.5377528667449951,\n",
       "  'test_macro_f1': 0.6758615654205608,\n",
       "  'test_micro_f1': 0.7431972789115646,\n",
       "  'test_pos_f1': 0.8235981308411214,\n",
       "  'test_accuracy': 0.7431972789115646,\n",
       "  'test_runtime': 0.3733,\n",
       "  'test_samples_per_second': 3150.701,\n",
       "  'test_steps_per_second': 393.838},\n",
       " (0.0001, 'l2', 0.01): {'test_loss': 0.5372947454452515,\n",
       "  'test_macro_f1': 0.6744694671238171,\n",
       "  'test_micro_f1': 0.7423469387755102,\n",
       "  'test_pos_f1': 0.8231173380035026,\n",
       "  'test_accuracy': 0.7423469387755102,\n",
       "  'test_runtime': 0.375,\n",
       "  'test_samples_per_second': 3136.299,\n",
       "  'test_steps_per_second': 392.037},\n",
       " (0.0001, 'l2', 0.005): {'test_loss': 0.5365754961967468,\n",
       "  'test_macro_f1': 0.6758615654205608,\n",
       "  'test_micro_f1': 0.7431972789115646,\n",
       "  'test_pos_f1': 0.8235981308411214,\n",
       "  'test_accuracy': 0.7431972789115646,\n",
       "  'test_runtime': 0.3702,\n",
       "  'test_samples_per_second': 3176.824,\n",
       "  'test_steps_per_second': 397.103},\n",
       " (1e-05, 'l1', 0.01): {'test_loss': 0.5372939109802246,\n",
       "  'test_macro_f1': 0.673714953271028,\n",
       "  'test_micro_f1': 0.7414965986394558,\n",
       "  'test_pos_f1': 0.822429906542056,\n",
       "  'test_accuracy': 0.7414965986394558,\n",
       "  'test_runtime': 0.3683,\n",
       "  'test_samples_per_second': 3192.878,\n",
       "  'test_steps_per_second': 399.11},\n",
       " (1e-05, 'l1', 0.005): {'test_loss': 0.5365563631057739,\n",
       "  'test_macro_f1': 0.6758615654205608,\n",
       "  'test_micro_f1': 0.7431972789115646,\n",
       "  'test_pos_f1': 0.8235981308411214,\n",
       "  'test_accuracy': 0.7431972789115646,\n",
       "  'test_runtime': 0.3757,\n",
       "  'test_samples_per_second': 3130.495,\n",
       "  'test_steps_per_second': 391.312},\n",
       " (1e-05, 'l2', 0.01): {'test_loss': 0.5372176766395569,\n",
       "  'test_macro_f1': 0.6729613193879012,\n",
       "  'test_micro_f1': 0.7406462585034015,\n",
       "  'test_pos_f1': 0.8217416715371128,\n",
       "  'test_accuracy': 0.7406462585034014,\n",
       "  'test_runtime': 0.3675,\n",
       "  'test_samples_per_second': 3199.958,\n",
       "  'test_steps_per_second': 399.995},\n",
       " (1e-05, 'l2', 0.005): {'test_loss': 0.5364736318588257,\n",
       "  'test_macro_f1': 0.6751058353263412,\n",
       "  'test_micro_f1': 0.7423469387755102,\n",
       "  'test_pos_f1': 0.8229105786090006,\n",
       "  'test_accuracy': 0.7423469387755102,\n",
       "  'test_runtime': 0.3684,\n",
       "  'test_samples_per_second': 3191.95,\n",
       "  'test_steps_per_second': 398.994},\n",
       " (1e-06, 'l1', 0.01): {'test_loss': 0.5372108817100525,\n",
       "  'test_macro_f1': 0.6729613193879012,\n",
       "  'test_micro_f1': 0.7406462585034015,\n",
       "  'test_pos_f1': 0.8217416715371128,\n",
       "  'test_accuracy': 0.7406462585034014,\n",
       "  'test_runtime': 0.3778,\n",
       "  'test_samples_per_second': 3112.544,\n",
       "  'test_steps_per_second': 389.068},\n",
       " (1e-06, 'l1', 0.005): {'test_loss': 0.5364626049995422,\n",
       "  'test_macro_f1': 0.6751058353263412,\n",
       "  'test_micro_f1': 0.7423469387755102,\n",
       "  'test_pos_f1': 0.8229105786090006,\n",
       "  'test_accuracy': 0.7423469387755102,\n",
       "  'test_runtime': 0.3725,\n",
       "  'test_samples_per_second': 3157.151,\n",
       "  'test_steps_per_second': 394.644},\n",
       " (1e-06, 'l2', 0.01): {'test_loss': 0.5372043251991272,\n",
       "  'test_macro_f1': 0.6729613193879012,\n",
       "  'test_micro_f1': 0.7406462585034015,\n",
       "  'test_pos_f1': 0.8217416715371128,\n",
       "  'test_accuracy': 0.7406462585034014,\n",
       "  'test_runtime': 0.3688,\n",
       "  'test_samples_per_second': 3188.579,\n",
       "  'test_steps_per_second': 398.572},\n",
       " (1e-06, 'l2', 0.005): {'test_loss': 0.5364550352096558,\n",
       "  'test_macro_f1': 0.6751058353263412,\n",
       "  'test_micro_f1': 0.7423469387755102,\n",
       "  'test_pos_f1': 0.8229105786090006,\n",
       "  'test_accuracy': 0.7423469387755102,\n",
       "  'test_runtime': 0.3699,\n",
       "  'test_samples_per_second': 3179.15,\n",
       "  'test_steps_per_second': 397.394}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Run for Audience Embeddings\n",
    "\n",
    "Use all data during training to generate the best embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_full_data(feature_types=['style_scaled', 'text_lemma_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 5874\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 73500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73500' max='73500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73500/73500 06:56, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.747200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.692300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.651200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.652400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.644600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.648900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.656800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.652300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.647700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.615700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.635600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.633500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.612800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.625500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.611500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.622500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.610400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.605100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.583300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.602300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.581900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.590300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.585600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.569400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.576800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.574600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.563900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.576500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.550100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.552700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.557500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.538800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.557500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.545500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.536100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.533900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.525600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.521200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.524700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.512700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.513000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.510600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.503600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.508800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.502800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.484200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.495900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.496600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.484300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.472900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>0.482600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.469100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.476200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.462300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>0.461500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.460200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>0.449300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.452600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>0.456100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.439900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>0.441700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.440800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.429100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>0.428800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.422300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>0.422600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.409800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>0.411100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.415100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>0.398000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../../../tmp/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-1500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-2000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-2500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-3000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-3500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-4000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-4500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-5000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-5500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-6000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-6500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-7000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-7500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-8000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-8500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-9000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-9500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-10500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-11000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-11500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-12000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-12500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-13000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-13500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-14000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-14500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-15000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-15500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-16000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-16500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-17000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-17500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-18000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-18500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-19000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-19500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-20000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-20500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-21000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-21500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-22000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-22500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-23000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-23500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-24000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-24500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-25000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-25500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-26000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-26500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-27000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-27500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-28000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-28500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-29000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-29500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-30000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-30500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-31000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-31500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-32000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-32500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-33000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-33500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-34000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-34500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-35000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-35500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-36000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-36500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-37000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-37500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-38000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-38500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-39000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-39500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-40000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-40500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-41000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-41500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-42000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-42500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-43000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-43500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-44000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-44500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-45000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-45500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-46000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-46500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-47000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-47500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-48000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-48500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-49000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-49500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-50000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-50500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-51000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-51500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-52000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-52500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-53000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-53500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-54000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-54500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-55000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-55500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-56000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-56500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-57000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-57500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-58000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-58500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-59000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-59500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-60000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-60500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-61000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-61500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-62000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-62500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-63000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-63500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-64000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-64500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-65000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-65500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-66000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-66500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-67000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-67500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-68000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-68500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-69000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-69500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-70000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-70500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-71000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-71500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-72000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-72500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-73000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ../../../../tmp/checkpoint-73500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=73500, training_loss=0.5384577696923496, metrics={'train_runtime': 416.7262, 'train_samples_per_second': 1409.559, 'train_steps_per_second': 176.375, 'total_flos': 0.0, 'train_loss': 0.5384577696923496, 'epoch': 100.0})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "D_in = len(data.iloc[0].feats)\n",
    "num_users = data.user_id.nunique()\n",
    "model_arguments = {'D_in': D_in, 'num_users': num_users, 'C': 1e-4, 'reg_type': 'l1'}\n",
    "\n",
    "model = IRTNet(**model_arguments)\n",
    "args = TrainingArguments(num_train_epochs=100, output_dir=\"../../../../tmp\", learning_rate=0.005, disable_tqdm=False, logging_steps=1000)\n",
    "\n",
    "data2 = data.to_dict(orient='records')\n",
    "\n",
    "trainer = Trainer(model=model, train_dataset=data2, args=args, eval_dataset=data2)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info = pd.read_csv('corpus-webis-editorial-quality-18_annotators-personality-traits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "W = model.users.weight.detach().cpu().numpy().T[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info['model_embed'] = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extraversion_num</th>\n",
       "      <th>agreeableness_num</th>\n",
       "      <th>conscientiousness_num</th>\n",
       "      <th>neuroticism_num</th>\n",
       "      <th>openness_num</th>\n",
       "      <th>model_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>extraversion_num</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.443956</td>\n",
       "      <td>0.108848</td>\n",
       "      <td>-0.624504</td>\n",
       "      <td>0.542754</td>\n",
       "      <td>-0.559358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agreeableness_num</th>\n",
       "      <td>0.443956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.552674</td>\n",
       "      <td>-0.778170</td>\n",
       "      <td>0.244179</td>\n",
       "      <td>-0.198169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conscientiousness_num</th>\n",
       "      <td>0.108848</td>\n",
       "      <td>0.552674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.539632</td>\n",
       "      <td>-0.206963</td>\n",
       "      <td>0.065663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuroticism_num</th>\n",
       "      <td>-0.624504</td>\n",
       "      <td>-0.778170</td>\n",
       "      <td>-0.539632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.267451</td>\n",
       "      <td>0.308043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openness_num</th>\n",
       "      <td>0.542754</td>\n",
       "      <td>0.244179</td>\n",
       "      <td>-0.206963</td>\n",
       "      <td>-0.267451</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.363471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_embed</th>\n",
       "      <td>-0.559358</td>\n",
       "      <td>-0.198169</td>\n",
       "      <td>0.065663</td>\n",
       "      <td>0.308043</td>\n",
       "      <td>-0.363471</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       extraversion_num  agreeableness_num  \\\n",
       "extraversion_num               1.000000           0.443956   \n",
       "agreeableness_num              0.443956           1.000000   \n",
       "conscientiousness_num          0.108848           0.552674   \n",
       "neuroticism_num               -0.624504          -0.778170   \n",
       "openness_num                   0.542754           0.244179   \n",
       "model_embed                   -0.559358          -0.198169   \n",
       "\n",
       "                       conscientiousness_num  neuroticism_num  openness_num  \\\n",
       "extraversion_num                    0.108848        -0.624504      0.542754   \n",
       "agreeableness_num                   0.552674        -0.778170      0.244179   \n",
       "conscientiousness_num               1.000000        -0.539632     -0.206963   \n",
       "neuroticism_num                    -0.539632         1.000000     -0.267451   \n",
       "openness_num                       -0.206963        -0.267451      1.000000   \n",
       "model_embed                         0.065663         0.308043     -0.363471   \n",
       "\n",
       "                       model_embed  \n",
       "extraversion_num         -0.559358  \n",
       "agreeableness_num        -0.198169  \n",
       "conscientiousness_num     0.065663  \n",
       "neuroticism_num           0.308043  \n",
       "openness_num             -0.363471  \n",
       "model_embed               1.000000  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info['party'] = user_info['id'].map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of Embeddings by Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f75ea4c4710>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_info.groupby('party').model_embed.hist(alpha=0.5, legend=True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison to other characteristics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='model_embed', ylabel='extraversion_num'>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_info.plot.scatter(x='model_embed', y='extraversion_num', color=['blue' if x=='L' else 'red' for x in user_info.party])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='model_embed', ylabel='openness_num'>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_info.plot.scatter(x='model_embed', y='openness_num', color=['blue' if x=='L' else 'red' for x in user_info.party])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
