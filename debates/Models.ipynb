{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irt_lib.data_helper import create_full_data\n",
    "\n",
    "from irt_lib.helpers import split_by_doc_id, do_metrics, run_full_cv\n",
    "\n",
    "from lirt_ib.models import  IdealNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"../data/debates/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style and Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data = create_full_data(feature_types=['style_quality_scaled'], label_type='bin_points', base_path=PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = len(style_data.iloc[0].feats)\n",
    "num_users = style_data.user_id.nunique()\n",
    "model_arguments = {'D_in': D_in, 'num_users': num_users, 'use_popularity': True}\n",
    "model_cls = IdealNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in [1e-3, 1e-4, 1e-5, 1e-6]:\n",
    "    for reg_type in ['l1', 'l2']:\n",
    "        for learning_rate in [0.01, 0.005]:\n",
    "            model_arguments['C'] = C\n",
    "            model_arguments['reg_type'] = reg_type\n",
    "            train_arguments['learning_rate'] = learning_rate\n",
    "            train_arguments['num_train_epochs'] = 20\n",
    "            results = run_full_cv(style_data, model_cls, model_arguments, train_arguments, averaged=True)\n",
    "            \n",
    "            final_results[(C, reg_type, learning_rate)] = results\n",
    "            \n",
    "            raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data = create_full_data(feature_types=['issues_speaker'], label_type='bin_points', base_path=PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "D_in = len(style_data.iloc[0].feats)\n",
    "num_users = style_data.user_id.nunique()\n",
    "model_arguments = {'D_in': D_in, 'num_users': num_users, 'use_popularity': True}\n",
    "model_cls = IdealNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arguments = {}\n",
    "for C in [1e-4, 1e-5, 1e-6]:\n",
    "    for reg_type in ['l1', 'l2']:\n",
    "        for learning_rate in [0.1, 0.01, 0.005]:\n",
    "            with open('log_file', 'a') as log_file:\n",
    "                log_file.write(f\"Starting {(C, reg_type, learning_rate)}\\n\")\n",
    "            model_arguments['C'] = C\n",
    "            model_arguments['reg_type'] = reg_type\n",
    "            train_arguments['learning_rate'] = learning_rate\n",
    "            train_arguments['num_train_epochs'] = 20\n",
    "            results = run_full_cv(style_data, model_cls, model_arguments, train_arguments, averaged=True)\n",
    "            \n",
    "            final_results[(C, reg_type, learning_rate)] = results\n",
    "            with open('log_file', 'a') as log_file:\n",
    "                log_file.write(f\"Results {str(results)}\\n\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(v['eval_accuracy'] for v in final_results.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Data and Speaker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data = create_full_data(feature_types=['style_quality_scaled', 'issues_speaker'], label_type='bin_points', base_path=PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(style_data.iloc[0].feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_v2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = len(style_data.iloc[0].feats)\n",
    "num_users = style_data.user_id.nunique()\n",
    "model_arguments = {'D_in': D_in, 'num_users': num_users, 'use_popularity': True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = IdealNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arguments = {}\n",
    "for C in [1e-4, 1e-5, 1e-6]:\n",
    "    for reg_type in ['l1', 'l2']:\n",
    "        for learning_rate in [0.1, 0.01, 0.005]:\n",
    "            with open('log_file', 'a') as log_file:\n",
    "                log_file.write(f\"Starting {(C, reg_type, learning_rate)}\\n\")\n",
    "            model_arguments['C'] = C\n",
    "            model_arguments['reg_type'] = reg_type\n",
    "            train_arguments['learning_rate'] = learning_rate\n",
    "            train_arguments['num_train_epochs'] = 20\n",
    "            results = run_full_cv(style_data, model_cls, model_arguments, train_arguments, averaged=True)\n",
    "            \n",
    "            final_results_v2[(C, reg_type, learning_rate)] = results\n",
    "            with open('log_file', 'a') as log_file:\n",
    "                log_file.write(f\"Results {str(results)}\\n\\n\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(final_results_v2, open('debate_speaker_style.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = len(style_data.iloc[0].feats)\n",
    "num_users = style_data.user_id.nunique()\n",
    "model_arguments = {'D_in': D_in, 'num_users': num_users, 'use_popularity': False}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arguments = {}\n",
    "for C in [1e-4, 1e-5, 1e-6]:\n",
    "    for reg_type in ['l1', 'l2']:\n",
    "        for learning_rate in [0.1, 0.01, 0.005]:\n",
    "            \n",
    "            model_arguments['C'] = C\n",
    "            model_arguments['reg_type'] = reg_type\n",
    "            train_arguments['learning_rate'] = learning_rate\n",
    "            train_arguments['num_train_epochs'] = 20\n",
    "            results = run_full_cv(style_data, model_cls, model_arguments, train_arguments, averaged=True)\n",
    "            \n",
    "            final_results_v2[(C, reg_type, learning_rate)] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in final_results_v2.items():\n",
    "    print(k, v['eval_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([v.get('eval_accuracy') for v in final_results_v2.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text + Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data = create_full_data(feature_types=['text_bin_lemma', 'style_quality_scaled'], label_type='bin_points', base_path=PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = len(style_data.iloc[0].feats)\n",
    "num_users = style_data.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arguments = {'D_in': D_in, 'num_users': num_users}\n",
    "train_arguments = {'num_train_epochs': 200, 'learning_rate': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = IRTNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in [1e-4, 1e-5]:\n",
    "    for reg_type in ['l1', 'l2']:\n",
    "        for learning_rate in [0.01, 0.005]:\n",
    "            model_arguments['C'] = C\n",
    "            model_arguments['reg_type'] = reg_type\n",
    "            train_arguments['learning_rate'] = learning_rate\n",
    "            train_arguments['num_train_epochs'] = 20\n",
    "            results = run_full_cv(style_data, model_cls, model_arguments, train_arguments, averaged=True)\n",
    "            \n",
    "            final_results[(C, reg_type, learning_rate)] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Embeddings Review\n",
    "\n",
    "Analyze embeddings from Style+Speaker Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names\n",
    "\n",
    "import pandas as pd\n",
    "p1 = pd.read_csv(PREFIX + '/style_quality_scaled.csv').columns[1:].tolist()\n",
    "p2 = pd.read_csv(PREFIX + '/issues_speaker.csv').columns[1:].tolist()\n",
    "\n",
    "feat_names = p1 + p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data = create_full_data(feature_types=['style_quality_scaled', 'issues_speaker'], label_type='bin_points', base_path=PREFIX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "D_in = len(style_data.iloc[0].feats)\n",
    "num_users = style_data.user_id.nunique()\n",
    "model_arguments = {'D_in': D_in, 'num_users': num_users, 'use_popularity': True, 'reg_type': 'l1'}\n",
    "\n",
    "model = IdealNet(**model_arguments)\n",
    "\n",
    "args = TrainingArguments(num_train_epochs=20, output_dir=\"../../../../tmp\", learning_rate=0.01, disable_tqdm=False, logging_steps=1000)\n",
    "\n",
    "train_data = style_data.to_dict(orient='records')\n",
    "\n",
    "trainer = Trainer(model=model, train_dataset=train_data, args=args, eval_dataset=train_data)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = model.popularity.weight.cpu().detach().numpy()[0]\n",
    "\n",
    "W2 = model.polarity.weight.cpu().detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(sorted(zip(W, feat_names))[:6])\n",
    "print('----')\n",
    "print(sorted(zip(W, feat_names))[-6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(zip(W2, feat_names))[:6])\n",
    "print('----')\n",
    "print(sorted(zip(W2, feat_names))[-6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "newp = [(a,b) for a, b in zip(W, W2)]\n",
    "plt.scatter(*zip(*newp), alpha=0.5)\n",
    "plt.xlabel('Weighs for Polarity')\n",
    "plt.ylabel('Weights for Popularity')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct user embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "people = json.load(open('users.json'))\n",
    "\n",
    "id_map_data = pd.read_csv('/home/ec2-user/final_paper_data_v2/debate_voter_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = model.users.weight.cpu().detach().numpy().T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "party_ideals = defaultdict(list)\n",
    "for name, idx in id_map_data.groupby(['voter_name', 'voter_id']).first().index.tolist():\n",
    "    if name in people:\n",
    "        party = people[name]['political_ideology']\n",
    "        weight = U[idx]\n",
    "        party_ideals[party].append(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alld = sorted(party_ideals.items())\n",
    "labels = [x[0] for x in alld if len(x[1]) > 50]\n",
    "points = [x[1] for x in alld if len(x[1]) > 50]\n",
    "plt.boxplot(points, labels=labels, showfliers=False)\n",
    "plt.xticks(rotation = 45) # Rotates X-Axis Ticks by 45-degrees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
