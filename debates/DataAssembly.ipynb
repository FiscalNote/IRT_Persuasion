{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Hack to import our models\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location where data will be stored\n",
    "PREFIX = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.cs.cornell.edu/~esindurmus/ddo.html\n",
    "data = pd.read_json(PREFIX + '/debates.json').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefiltering\n",
    "\n",
    "First, the debates are filtered down to the set that meets the minimum criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.participant_1_status != 'Tied']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debate must have vote\n",
    "data = data[data.votes.map(lambda x: len(x) > 0)]\n",
    "\n",
    "# Some debates have a forfeit label - for others we check the text\n",
    "data['has_forfeit'] = data.rounds.map(lambda x: any('forfeit' in t['text'].lower() for round in x for t in round))\n",
    "data = data[~data.has_forfeit]\n",
    "data = data[data.forfeit_label == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of debates with weird vote style\n",
    "data = data[data.votes.map(lambda x: 'Who won the debate' not in str(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some debates have weird empty rounds\n",
    "data['rounds'] = data.rounds.map(lambda xs: [x for x in xs if len(x) == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep debates with three or more rounds\n",
    "data = data[data.rounds.map(lambda x: len(x) >= 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must have 100+ words\n",
    "s1 = data.rounds.map(lambda xs: len(' '.join([z[0]['text'] for z in xs]).split()))\n",
    "data = data[s1 > 100]\n",
    "s2 = data.rounds.map(lambda xs: len(' '.join([z[1]['text'] for z in xs]).split()))\n",
    "data = data[s2 > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOD_CATEGORIES = ['Politics', 'Religion', 'Society', 'Philosophy', 'Education', 'Economics']\n",
    "data = data[data.category.isin(GOOD_CATEGORIES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick debates that appear to have at least moderate engagement\n",
    "data = data[(data.participant_1_points + data.participant_2_points) >= 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.url = data.url.map(lambda x: x.replace('http://www.debate.org/debates/', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json(PREFIX + '/debates_filtered.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, transform into separate rows by \"side\". Each one will be a separate datapoint, so each user gets two per debate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_clean(t):\n",
    "    t = t.replace('\\n', ' ').replace('&gt', '').replace('\\r', ' ').replace('\\t', ' ').replace('  ', ' ').replace('  ', ' ')\n",
    "    \n",
    "    return t\n",
    "\n",
    "sep_data = []\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "\n",
    "    first_round = row.rounds[0]\n",
    "    \n",
    "    # Another weird edge case?\n",
    "    if len(first_round) != 2:\n",
    "        continue\n",
    "        \n",
    "    sides = {first_round[0]['side']: quick_clean(first_round[0]['text']),\n",
    "             first_round[1]['side']: quick_clean(first_round[1]['text'])}\n",
    "    \n",
    "    sides_full = {'Pro': [quick_clean(arg['text']) for round in row.rounds for arg in round if arg['side'] == 'Pro'],\n",
    "                  'Con': [quick_clean(arg['text']) for round in row.rounds for arg in round if arg['side'] == 'Con']}\n",
    "    \n",
    "    winning_side = None\n",
    "    winner_name = None\n",
    "    \n",
    "    if row.participant_1_status == 'Winning':\n",
    "        winning_side = row.participant_1_position\n",
    "        \n",
    "        winner_name = row.participant_1_name\n",
    "        loser_name = row.participant_2_name\n",
    "        \n",
    "        win_points = row.participant_1_points\n",
    "        lose_points = row.participant_2_points\n",
    "        \n",
    "        win_went_first = True\n",
    "    else: \n",
    "        winning_side = row.participant_2_position\n",
    "        winner_name = row.participant_2_name\n",
    "        loser_name = row.participant_1_name\n",
    "        \n",
    "        win_points = row.participant_2_points\n",
    "        lose_points = row.participant_1_points\n",
    "        \n",
    "        win_went_first = False\n",
    "    \n",
    "    \n",
    "    losing_side = 'Pro' if winning_side == 'Con' else 'Con'\n",
    "    \n",
    "    # Regardless of vote, count how many minds were changed\n",
    "    now_agree = 0\n",
    "    affirm = 0\n",
    "    detract = 0\n",
    "    for vote in row.votes:\n",
    "        v = vote['votes_map'][winner_name]\n",
    "        if len(v) == 1:\n",
    "            continue\n",
    "        if not v['Agreed with before the debate'] and v['Agreed with after the debate']:\n",
    "            now_agree += 1\n",
    "        if v['Agreed with before the debate'] and v['Agreed with after the debate']:\n",
    "            affirm += 1\n",
    "        if v['Agreed with before the debate'] and not v['Agreed with after the debate']:\n",
    "            detract += 1\n",
    "    \n",
    "    \n",
    "    win_data = {'name': winner_name, \n",
    "                'first_text': sides[winning_side], \n",
    "                 'text': sides_full[winning_side],                \n",
    "                'position': winning_side, \n",
    "                'won': True, \n",
    "                'url': row.url,\n",
    "                'category': row.category,\n",
    "                'title': row.title,\n",
    "                'challenged': now_agree,\n",
    "                'affirmed': affirm,\n",
    "                'detracted': detract,\n",
    "                'total_voters': row.number_of_votes,\n",
    "                'total_points': win_points,\n",
    "                'went_first': win_went_first}\n",
    "    \n",
    "    \n",
    "    # Same table for the opposite side\n",
    "    now_agree = 0\n",
    "    affirm = 0\n",
    "    detract = 0\n",
    "    for vote in row.votes:\n",
    "        \n",
    "        v = vote['votes_map'][loser_name]\n",
    "        if len(v) == 1:\n",
    "            continue\n",
    "        \n",
    "        if not v['Agreed with before the debate'] and v['Agreed with after the debate']:\n",
    "            now_agree += 1\n",
    "        if v['Agreed with before the debate'] and v['Agreed with after the debate']:\n",
    "            affirm += 1\n",
    "        if v['Agreed with before the debate'] and not v['Agreed with after the debate']:\n",
    "            detract += 1\n",
    "    \n",
    "    lose_data = {'name': loser_name, \n",
    "                 'first_text': sides[losing_side], \n",
    "                 'text': sides_full[losing_side],\n",
    "                 'position': losing_side, \n",
    "                 'won': False,\n",
    "                 'url': row.url, \n",
    "                 'category': row.category, \n",
    "                 'title': row.title,\n",
    "                 'challenged': now_agree,\n",
    "                 'affirmed': affirm,\n",
    "                 'detracted': detract,\n",
    "                 'total_voters': row.number_of_votes,\n",
    "                 'total_points': lose_points,\n",
    "                 'went_first': not win_went_first}\n",
    "    \n",
    "    sep_data.append(win_data)\n",
    "    sep_data.append(lose_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame(sep_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['debate_side_id'] = data2['url'] + data2['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_json(PREFIX + '/debates_filtered_by_side.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a list of features for \"usable\" users - aka those that have voted at least 10 times and agreed with someone after the debate at least once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "voter_counts = Counter()\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "    \n",
    "    for voter in row.votes:\n",
    "        voter_counts[voter['user_name']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(voter_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voters = [k for k, v in voter_counts.items() if v >= 10]\n",
    "\n",
    "len(data), len(voters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "had_opine = defaultdict(lambda: False)\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "    \n",
    "    for voter in row.votes:\n",
    "        for name, side in voter['votes_map'].items():\n",
    "            if name == 'Tied':\n",
    "                continue\n",
    "            if side['Agreed with after the debate']:\n",
    "                had_opine[voter['user_name']] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used agreed with at least once\n",
    "user_with_opine = [user for user in voters if had_opine[user] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review debate list for those containig one of these users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_user_present = []\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "    if any(u['user_name'] in voters for u in row.votes):\n",
    "        good_user_present.append(True)\n",
    "    else:\n",
    "        good_user_present.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated set\n",
    "data = data[good_user_present]\n",
    "data.to_json(PREFIX + '/debates_filtered.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2[data2.url.isin(data.url)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop('index', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_json(PREFIX + '/debates_filtered_by_side.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data), len(data2), len(voters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a table with rows for every voter+debate-side pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_data = pd.read_json(PREFIX + '/debates_filtered_by_side.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_voter_data = []\n",
    "\n",
    "for _, row in side_data.iterrows():\n",
    "    all_vote_info = data[data.url == row.url].iloc[0].votes\n",
    "    \n",
    "    for voter_data in all_vote_info:\n",
    "        if voter_data['user_name'] in voters:\n",
    "            \n",
    "            full_voter_data.append([voter_data['user_name'], row['debate_side_id'], row['name'], row['url'], \n",
    "                                    voter_data['votes_map'][row['name']]])\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_voter_data = pd.DataFrame(full_voter_data, columns=['voter_name', 'debate_side_id', 'speaker_name','url', 'vote_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_voter_data['points'] = full_voter_data.vote_info.map(lambda x: x['Total points awarded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_voter_data['affirmed'] = full_voter_data.vote_info.map(lambda x: x.get('Agreed with before the debate') & x.get('Agreed with after the debate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_voter_data['agree_after'] = full_voter_data.vote_info.map(lambda x: x.get('Agreed with after the debate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_voter_data['challenged'] = full_voter_data.vote_info.map(lambda x: (not x.get('Agreed with before the debate')) & x.get('Agreed with after the debate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = list(set(full_voter_data.voter_name))\n",
    "\n",
    "full_voter_data['voter_id'] = full_voter_data.voter_name.map(lambda x: vv.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_voter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mystery issue\n",
    "full_voter_data = full_voter_data.drop_duplicates(['voter_name', 'debate_side_id', 'speaker_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_voter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_voter_data.to_csv(PREFIX + '/debate_voter_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who did the particular voter give more points?\n",
    "full_win_map = {}\n",
    "for ids, rows in full_voter_data.groupby(['url', 'voter_name']):\n",
    "    if len(rows) != 2:\n",
    "        print(\"??\")\n",
    "        continue\n",
    "    p1 = int(rows.iloc[0].points)\n",
    "    p2 = int(rows.iloc[1].points)\n",
    "    if p1 > p2:\n",
    "        full_win_map[(ids[0], ids[1], rows.iloc[0].speaker_name)] = True\n",
    "        full_win_map[(ids[0], ids[1], rows.iloc[1].speaker_name)] = False\n",
    "\n",
    "    elif p2 > p1: \n",
    "        full_win_map[(ids[0], ids[1], rows.iloc[1].speaker_name)] = True\n",
    "        full_win_map[(ids[0], ids[1], rows.iloc[0].speaker_name)] = False\n",
    "\n",
    "    else:\n",
    "        full_win_map[(ids[0], ids[1], rows.iloc[0].speaker_name)] = 'Tie'\n",
    "        full_win_map[(ids[0], ids[1], rows.iloc[1].speaker_name)] = 'Tie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_voter_data['more_points'] = full_voter_data.apply(lambda row: full_win_map.get((row.url, row.voter_name, row.speaker_name)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_voter_data.more_points.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the ties\n",
    "full_voter_data = full_voter_data[full_voter_data.more_points != 'Tie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_voter_data.to_csv(PREFIX + '/debate_voter_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = full_voter_data[['debate_side_id', 'voter_id', 'more_points']]\n",
    "small.columns = ['doc_id', 'user_id', 'y_bin_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small.to_csv(PREFIX + '/debates/vote_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Creation\n",
    "\n",
    "## Style features\n",
    "\n",
    "- LIWC\n",
    "- Text Blob sentiment/subjectivity\n",
    "-  cmv_concrete', 'cmv_valence','cmv_arousal', 'cmv_dominance' (CMV annotated b/c thats the paper that used them)\n",
    "- MPQA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from irt_lib.smart_spacy import load_custom_spacy, get_style_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = load_custom_spacy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all round texts for pre-processing\n",
    "side_data['text'] = side_data.text.map(lambda x: ' '.join(x).strip().replace('  ', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = []\n",
    "i = 0\n",
    "from tqdm import tqdm\n",
    "\n",
    "for doc in tqdm(side_data.text, mininterval=300, miniters=100):\n",
    "    feat = get_style_features(doc, nlp)\n",
    "    final_features.append(feat)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_features), len(side_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data = pd.DataFrame(final_features, index=side_data.debate_side_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = style_data.lemmas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas.to_csv(PREFIX + '/debate_by_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data = style_data.drop('lemmas', axis=1)\n",
    "style_data = style_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_data = pd.read_csv('LIWC2015 Results (debates_filtered_by_side (1).csv).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_data = liwc_data[liwc_data.columns[15:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_data = liwc_data.set_index('P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_map = {k:f'liwc_{k.lower()}' for k in liwc_data.columns}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_data = liwc_data.rename(columns=column_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data = pd.concat([liwc_data, style_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data.to_csv(PREFIX + '/debates/style.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce scaled copy of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data = pd.read_csv(PREFIX + '/debates/style.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = style_data.values\n",
    "vals2 = ss.fit_transform(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_style_data_v2 = pd.DataFrame(vals2, index=style_data.index, columns=style_data.columns)\n",
    "all_style_data_v2.columns = [f'{x}_scaled' for x in all_style_data_v2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_style_data_v2.to_csv(PREFIX + '/debates/style_scaled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debate_data = pd.read_json(PREFIX + '/debates_filtered_by_side.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = debate_data.text.map(lambda x: ' '.join(x).strip().replace('  ', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec2 = TfidfVectorizer(min_df=5, max_features=10000)\n",
    "X = vec2.fit_transform(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.DataFrame(X.A, columns=vec2.get_feature_names(), index=debate_data.debate_side_id)\n",
    "text_df.to_csv(PREFIX + '/debates/text_raw_tfidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess lemmatized copy of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = pd.read_csv(PREFIX + '/debate_by_lemmas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "lemmas['lemmas2'] = lemmas.lemmas.map(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1 = CountVectorizer(binary=True, preprocessor=lambda x: x, tokenizer=lambda x: [y.lower() for y in x if y.isalpha()], max_features=10000, min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textX = vec1.fit_transform(lemmas.lemmas2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vec1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.DataFrame(textX.A, columns=vec1.get_feature_names(), index=lemmas.debate_side_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.to_csv(PREFIX + '/debates/text_lemma_bin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument Quality\n",
    "\n",
    "Model trained separately - see `irt_lib/quality_model.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.quality_model import QualityModelLabeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "qmodel = QualityModelLabeler(path=os.path.expanduser('~/final_paper_data_v2/models/final_ibm_quality/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "all_features = []\n",
    "for _, row in tqdm(debate_data.iterrows(), mininterval=350, total=len(debate_data)):\n",
    "    text = ' '.join(row.text)\n",
    "    \n",
    "    stats = qmodel.label_sent_stats(text)\n",
    "    all_features.append(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_feats = pd.DataFrame(all_features)\n",
    "ibm_feats.index = debate_data.debate_side_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_feats.columns = [f'ibm_{c}' for c in ibm_feats.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data = pd.read_csv(PREFIX + '/debates/style.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = pd.concat([style_data, ibm_feats], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.to_csv(PREFIX + '/debates/style_quality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(ibm_feats.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, index=ibm_feats.index, columns=ibm_feats.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_data = pd.read_csv(PREFIX + '/debates/style_scaled.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = pd.concat([style_data, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.to_csv(PREFIX + '/debates/style_quality_scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/users.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-1968333e777a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Download from https://www.cs.cornell.edu/~esindurmus/ddo.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muser_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPREFIX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/users.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdebate_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPREFIX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/debates_filtered_by_side.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/users.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Download from https://www.cs.cornell.edu/~esindurmus/ddo.html\n",
    "user_info = json.load(open(PREFIX + '/users.json'))\n",
    "\n",
    "debate_data = pd.read_json(PREFIX + '/debates_filtered_by_side.json')\n",
    "debate_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rows = []\n",
    "for _, row in debate_data.iterrows():\n",
    "    if row['name']  in user_info:\n",
    "        cur_info = user_info[row['name']]\n",
    "        \n",
    "        issue_pairs = sorted(cur_info['big_issues_dict'].items())\n",
    "        issue_vec = [1 if pos == 'Pro' else -1 if pos == 'Con' else 0 for _, pos in issue_pairs]\n",
    "        person_vec = {'political_ideology': cur_info.get('political_ideology'),\n",
    "                       'religious_ideology': cur_info.get('religious_ideology'), \n",
    "                       'pol_party': cur_info.get('party')}\n",
    "        user_rows.append((issue_vec, person_vec))\n",
    "    else:\n",
    "        # Add blanks\n",
    "        person_vec = {'political_ideology': None,\n",
    "                       'religious_ideology': None, \n",
    "                       'pol_party': None}\n",
    "        \n",
    "        user_rows.append(([0] * 48, person_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the categorial features\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dv = DictVectorizer()\n",
    "\n",
    "vals = [v[1] for v in user_rows]\n",
    "\n",
    "new_vals = dv.fit_transform(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Just normally extract the Big Issue features\n",
    "p1 = np.array([v[0] for v in user_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_names = [x[0] for x in issue_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_info = np.concatenate([p1, new_vals.A], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = issue_names + dv.feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_features = pd.DataFrame(all_user_info, columns=all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_features.drop('pol_party', axis=1, inplace=True)\n",
    "all_user_features.drop('religious_ideology', axis=1, inplace=True)\n",
    "all_user_features.drop('political_ideology', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_features['debate_side_id'] = debate_data.debate_side_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_features.set_index('debate_side_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_features.to_csv(PREFIX + '/debates/full_speaker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_only = all_user_features[all_user_features.columns[:48]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_only.to_csv(PREFIX + '/debates/issues_speaker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X2 = StandardScaler().fit_transform(issues_only.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_only_scaled = pd.DataFrame(X2, index=issues_only.index, columns=issues_only.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_only_scaled.to_csv(PREFIX + '/debates/issues_speaker_scaled.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
